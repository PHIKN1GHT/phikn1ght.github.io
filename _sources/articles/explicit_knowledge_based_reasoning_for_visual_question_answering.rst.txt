.. post:: 2019-8-17
	:tags: 文献导读, 知识库, 视觉问答, 
	:author: φKN1GHT

[导读]针对视觉问答的基于知识库的显式推理
==========================================

摘要
----

本文提出了一种能够根据大型知识库里提取出的信息对图像上的内容进行推理的视觉问答方法。其不仅可以给出回答和响应的解释（推理过程），还能够回答比基于LSTM的方法更加复杂的问题。除此之外，本文还提供了一个数据集和评估此类方法的可靠标准。

原文：Explicit Knowledge-based Reasoning for Visual Question Answering(https://arxiv.org/abs/1511.02570)

引入
----

1. 大多数视觉问答方法无法处理显示逻辑推理

2. 主流方法：CNN提取图像特征，丢给LSTM处理。其特点有：

* 对于图像内容直接相关的问题能够很好地回答

* 缺乏可解释性，造成无法排除过拟合的可能

* LSTM能编码的信息量相当有限，如果要效果好需要超级大的LSTM

* 只能在非常首先的场景下进行显式推理

3. 提出Ahab方法：先检测出图像的相关内容，再将问题转化为知识库上的查询，然后再把查询拿来在图像的内容与知识库上跑。特点：

* 能够处理复杂的依赖于图像内容之外的问题

研究背景
--------

1. 初代VQA方法：用语义分析+贝叶斯推理

2. 主流：CNN+LSTM，两大类：用独立/相同的LSTM处理问题和回答

3.  回答人类照着图片提出的问题不可避免地需要引入外部的信息。[常识]在某种程度上，整个训练集会提供一些这样的信息，但本身是不灵活也难以扩展，也无法提供回答问题所需的背景信息。这导致难以生成一个大多数VQA方法实际上可以回答的数据集。

4. 通过构建大规模结构化知识库，知识可以被高效地编码与查询。流行的知识库主要由众包/手工标注的DBpedia,Freebase和Wikidata等，和自动提取的无结构/半结构化的YAGO, OpenIE, NELL和NEIL等。本文使用了DBpedia

5. DBpedia知识库提取自Wikipedia，相对其他数据库来说更加准确，对本体的定义也更加完善。

6. 可以通过一种范式转换将VQA转变成KBQA：吧图像特征和场景标签视作结点，用结点间的无向边表征互相兼容/不互相兼容的关系。同时，把问题转化成RDMBS查询语句。

7. 我们提供的数据集中，问题由模板生成（分为视觉、常识和知识库推理三类），其中我们假定人类回答知识库推理问题时可以借助维基百科。

