.. post:: 2019-8-30
    :tags: ICPC
    :author: φKN1GHT
    :exclude:

    八月末，久违地再一次和 `@HicoderDR <https://github.com/HicoderDR>`_ 一起来到了南京城。之前曾两次造访过这里，分别是来参加“南京四校骇客马拉松”和“全国大学生智能互联大赛全国决赛”。十分巧合的是，这两场比赛最后的结局都非常惨淡，只能无奈地抱憾而归……

CCF ADL104《新一代视觉计算》课程内容回顾（Day1）
================================================

.. contents:: 文章目录
    :depth: 4

引言
----

八月末，久违地再一次和 `@HicoderDR <https://github.com/HicoderDR>`_ 一起来到了南京城。之前曾两次造访过这里，分别是来参加“南京四校骇客马拉松”和“全国大学生智能互联大赛全国决赛”。十分巧合的是，这两场比赛最后的结局都非常惨淡，只能无奈地抱憾而归。而这一次，则是以求学的心态拜访这里，主要是希望为自己的大学生创新创业计划项目寻求一些研究灵感。在南京逗留的四天，我都下榻在了在信息工程大学地铁站附近的七天优品里。

整整三天上午三小时下午三小时的学术报告，确实十分累人，但收获也非常丰富，接触到了许多十分具有价值的新思想，因而略加整理记录于此，希望能为之后的学术工作提供参考。

《跨媒体智能：表征、分析与应用》
--------------------------------

主讲人：彭宇新（\ `北京大学 计算机科学技术研究所 多媒体信息处理研究室 <http://www.icst.pku.edu.cn/mipl/>`_ \ `Github主页 <https://github.com/PKU-ICST-MIPL>`_）

研究背景
++++++++

据卫报统计，视频、图像等多媒体数据已经占据了大数据超过90%的比重，跨媒体指由图像、视频、文本、音频等形式上多源异构，语义上相互关联的互相融合的媒体形态

传统人工智能：文本推理

实际上：多源信息的共同参与

存在的问题
**********

* 语义鸿沟：视频图像的计算机特征表示与人类理解的语义概念不一致

* 异构鸿沟：视频图像包含的视觉、语言等不同模态信息的特征表示不一致

研究难点
********

* 如何综合利用多模态信息缩短语义鸿沟？

* 如何实现多模态信息的统一表征和综合利用？

主要任务
++++++++

* 跨媒体统一表征理论和模型

 * 通过统一表征映射，将表达相似语义的跨媒体数据映射到同一个空间中，转换为相似的统一表征

* 跨媒体关联理解与深度挖掘

 * 挖掘跨媒体知识，补充和拓展传统的基于文本的知识体系，研究跨媒体数据关联与融合方法

 * 如何深入理解跨媒体数据关联，实现相似性计算与知识挖掘，是当前研究的重要挑战

* 跨媒体知识图谱构建与学习

 * 当前跨媒体分析方法以数据驱动为主，可解释性与可泛化能力不足；需研究知识驱动的跨媒体分析方法

 * 如何构建跨媒体知识图谱，形成跨媒体知识表达与学习的方法体系，为知识驱动方法提供重要依托

研究思想
++++++++

知识驱动的跨媒体协同推理

研究成果
+++++++++

1. 细粒度图像分类
*****************

* The Application of Two-level Attention Models in Deep Convolutional Neural Network for Fine-grained Image Classification

* Object-Part Attention Model for Fine-grained Image Classification

.. note::

	为了减少标注依赖，提出空间拓扑注意力学习方法，仅使用图像级标注信息，通过卷积激励的显著分布估计与拓扑关联约束的语义对齐，自动定位对象、部件显著区域，实现图像细粒度辨识与分类

* Only Learn One Sample: Fine-Grained Visual Categorization with One Sample Training

.. note::

	针对一个训练样本条件下的图像细分类，提出了基于选择与生成的数据增广方法，通过多示例学习与对抗生成，对数据进行分割、过滤、再选择和生成，实现图像数据的多样性扩增

* Which and How Many Regions to Gaze: Focus Discriminative Regions for Fine-grained Visual Categorization

* StackDRL: Stacked Deep Reinforcement Learning for Fine-grained Visual Categorization

.. note::

	为了提升图像细分类准确率，提出多尺度堆叠式深度强化学习方法，序列式地定位不同尺度的对象及其显著区域，并自动选择显著区域的数目，避免现有方法依赖人工先验和实验调参造成的扩展性上的局限

* Fine-grained Discriminative Localization via Saliency-guided Faster R-CNN

* Fast Fine-grained Image Classification via Weakly Supervised Discriminative Localization

.. note::

	针对图像细分类的速度问题，提出了多级注意力引导的快速辨识定位方法，通过多级注意力提取网络与辨识性定位网络，实现了细粒度分类与辨识性区域定位的协同促进，在提升分类准确率的同时，实现分类加速


* Error-Driven Incremental Learning in Deep Convolutional Neural Network for Large-Scale Image Classification

.. note::

	针对新增类别训练加速问题，提出层次化深度增量迁移学习方法，通过类别划分的层次化模型与特征迁移的增量训练，对模型进行动态扩容与知识迁移，解决了新增类别训练加速的难题

* Fine-grained Image Classification via Combining Vision and Language

.. note::

	提出多源语义嵌入的视觉表示方法, 通过显著协同优化的视觉分支和卷积序列编码的文本分支，挖掘图像文本的语义关联和嵌入表示学习，突破单源信息表示的局限性

2. 构建细粒度跨媒体检索数据集和评测基准PKU FG-XMedia
****************************************************

* A New Benchmark and Approach for Fine-grained Cross-media Retrieval

.. note::

	首个包含多达4种媒体类型（图像、文本、视频、音频）的细粒度跨媒体检索公开数据集和评测基准，涵盖200个细粒度类别（鸟大类下的200个子类，如灰翅鸥、灰背鸥、加州海鸥、黑背鸥等）。

3. 跨媒体检索——跨媒体共享语义空间映射
*************************************

* Semi-Supervised Cross-Media Feature Learning with Unified Patch Graph Regularization

.. note::

	针对多种媒体的统一表征问题，提出图规约共享语义空间映射方法，建立跨媒体统一关联超图模型，将多种媒体的全局、局部信息以及它们之间的复杂关联关系建模在一个超图中，同时学习多种媒体的统一表征

* CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning

.. note::

	针对深度跨媒体统一表征学习，提出了跨媒体生成式对抗网络，构建跨媒体卷积自编码器，通过媒体内和媒体间的对抗训练拟合不同媒体数据的联合分布，提升了跨媒体关联学习的效果

* Cross-media Shared Representation by Hierarchical Learning with Multiple Deep Networks

* CCL: Cross-modal Correlation Learning with Multi-grained Fusion by Hierarchical Network

.. note::

	针对深度跨媒体细粒度建模问题，提出层叠式耦合关联学习方法，有效融合粗、细粒度的语义表示，动态平衡媒体内与媒体间的关联关系，提高检索准确率


* Cross-media Multi-level Alignment with Relation Attention Network

.. note::

	针对细粒度局部关系建模，提出视觉-语言关系注意力模型，建立多级对齐网络，同时建模图像和文本之间全局、局部以及局部关系三个级别的语义对齐，有效促进跨媒体关联检索效果


4. 跨媒体检索——跨媒体非对称关系映射
***********************************

* Modality-specific Cross-modal Similarity Measurement with Recurrent Attention Network

.. note::

	针对视觉-语言之间信息不对等问题，提出了特定媒体语义空间映射方法，充分学习不同媒体之间不平衡的关联信息，有效挖掘不同媒体语义空间的互补性，提高了跨媒体关联检索效果


* Cross-modal Bidirectional Translation via Reinforcement Learning

.. note::

	针对视觉-语言信息的相互转换问题，提出了跨媒体双向翻译模型，借鉴机器翻译的思想并建立跨媒体强化学习策略，通过媒体间和媒体内两种奖励的相互促进，提升跨媒体关联学习效果

* Show and Tell in the Loop: Cross-Modal Circular Correlation Learning

.. note::

	针对视觉-语言信息相互生成问题，提出了跨媒体循环关联学习方法，同时进行图像-文本相互生成及统一表征，通过循环训练及数据增广使不同任务相互促进，提升跨媒体关联学习效果

5. 跨媒体检索——跨媒体模型训练问题
*********************************

* MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal Retrieval

* Deep Cross-media Knowledge Transfer

.. note::

	针对跨媒体数据标注成本大的问题，提出混合知识迁移方法，通过模态共享的混合迁移网络与模态对抗的表征学习策略，仅使用包含单一媒体的源域数据，支持跨媒体目标域的模型训练

* Life-long Cross-media Correlation Learning

.. note::

	针对新增跨媒体数据的模型训练问题，提出了跨媒体终身学习方法，建立高层知识共享及自适应网络扩容机制，通过域内分布对齐和域间知识蒸馏，利用知识迁移促进新增数据关联学习

* Zero-shot Cross-media Embedding Learning with Dual Adversarial Distribution Network

* Dual Adversarial Networks for Zero-shot Cross-media Retrieval

.. note::

	针对新增未知数据的检索问题，提出零样本跨媒体对偶对抗学习方法，通过生成对抗网络构成对偶结构以挖掘数据潜在结构信息，利用类别词嵌入进行知识迁移，实现零样本跨媒体检索

6. 跨媒体检索——跨媒体快速检索
*****************************

* Multi-Scale Correlation for Sequential Cross-modal Hashing Learning

* Sequential Cross-Modal Hashing Learning via Multi-scale Correlation Mining

.. note::

	针对有监督条件下哈希码鲁棒性问题，提出序列化多尺度特征哈希方法，通过多尺度特征指导学习和尺度间关联挖掘，提高了哈希码的多样性和鲁棒性，实现更好的检索结果

* SCH-GAN: Semi-supervised Cross-modal Hashing by Generative Adversarial Network

.. note::

	针对半监督条件下的哈希码生成问题，提出半监督跨媒体生成对抗哈希方法：通过生成对抗网络用无标注数据构造边界样本以增强训练；通过离散策略梯度优化生成器实现高效哈希检索

* Unsupervised Generative Adversarial Cross-modal Hashing

.. note::

	针对无监督条件下的哈希码生成问题，提出无监督跨媒体生成对抗哈希方法：通过关联图模型建模数据流形结构，利用流形结构上的潜在关联，实现无监督的高效哈希检索


7. 构建跨媒体检索数据集PKU XMedia
*********************************

.. note::

	* **媒体多样**：5种媒体类型（图像、文本、视频、音频、3D）。
	* **数据量大**：超过10万标注数据，200个语义类别，基于wordNet层次结构。
	* **语义明确**：语义类别为具体的物体（如Dog、Airplane等），避免语义混淆。
	* **来源权威**：数据来自著名网站如Wikipedia, Flickr, Youtube, Findsounds, Freesound, Yobi3D同时具备数据量、媒体多样性上的优势，能够全面评测跨媒体相关方法在实际大规模、多样化数据条件下的性能。

8. 视频描述生成
***************
* Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning

.. note::

	针对视频细粒度时空信息建模问题，提出对象感知双向图方法，从正时序和逆时序方向建立互补的双向时序图，通过建模多个对象动态时序轨迹，生成描述对象时序演化的自然语言文本

* Hierarchical Vision-Language Alignment for Video Captioning

.. note::

	针对视频和文本语句语义一致性建模问题，提出层次化视觉-语言对齐方法，通过二元记忆循环网络利用视觉内容与本文语句之间不同粒度的隐含对齐关系，指导生成准确的视频文本描述

9. 文本到图像生成
*****************

* Text-to-image Synthesis via Symmetrical Distillation Networks

.. note::

	提出对称蒸馏网络方法，通过蒸馏学习机制，将知识从通用判别网络迁移到具有对称结构的图像生成网络中，建立文本空间到图像空间的映射，生成与文本内容相符的图像

《从粗放式到集约式：针对复杂数据的鲁棒深度学习方法》
----------------------------------------------------













总结
----


















































